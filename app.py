import streamlit as st
import google.generativeai as genai
import PyPDF2
import os
import requests
from bs4 import BeautifulSoup
from youtube_transcript_api import YouTubeTranscriptApi
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# --- 1. ×”×’×“×¨×•×ª ×“×£ ×•×¢×™×¦×•×‘ CSS ××ª×§×“× (×©×•××¨ ×¢×œ ×›×œ ×”×ª×™×§×•× ×™×) ---
st.set_page_config(page_title="××¨×›×– ×™×“×¢ ×”× ×“×¡×™", layout="wide", page_icon="âš™ï¸")

st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Heebo:wght@300;400;700&display=swap');
    
    html, body, [class*="css"] {
        font-family: 'Heebo', sans-serif;
    }
    
    /* ×™×™×©×•×¨ ×œ×™××™×Ÿ ×©×œ ××œ×× ×˜×™× ×˜×§×¡×˜×•××œ×™×™× ×‘×¡×™×¡×™×™× */
    .stMarkdown, .stText, h1, h2, h3, h4, h5, h6, label, .stSelectbox, .stTextInput {
        direction: rtl !important;
        text-align: right !important;
    }
    
    /* ×ª×™×§×•×Ÿ ×™×™×¢×•×“×™ ×œ×¨×©×™××•×ª (×‘×•×œ×˜×™× ×•××¡×¤×¨×™×) */
    .stMarkdown p, .stMarkdown li {
        direction: rtl !important;
        text-align: right !important;
    }
    .stMarkdown ul, .stMarkdown ol {
        direction: rtl !important;
        padding-right: 2.5rem !important;
        padding-left: 0 !important;
        text-align: right !important;
    }
    
    /* ×”×¢×œ××ª ×›×¤×ª×•×¨ ×”×›×™×•×•×¥ ×©×œ ×ª×¤×¨×™×˜ ×”×¦×“ - ×¤×•×ª×¨ ××ª ×‘××’ ×”××¨×˜×™×¤×§×˜ */
    [data-testid="collapsedControl"] {
        display: none !important;
    }
    
    /* ×ª×™×§×•×Ÿ ×”×¨××˜×™ ×œ× ×•×¡×—××•×ª (KaTeX) */
    .katex, .katex-display, .katex * {
        direction: ltr !important;
        unicode-bidi: isolate !important;
    }
    .katex-display {
        text-align: center !important;
        margin: 1.5rem auto !important;
        display: block;
    }
    span.katex {
        display: inline-block;
        direction: ltr !important;
    }
    
    /* ×¢×™×¦×•×‘ ×›×•×ª×¨×ª ×¨××©×™×ª */
    .main-header {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
        color: white;
        padding: 2rem;
        border-radius: 12px;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    .main-header h1 {
        color: white;
        font-size: 2.8rem;
        margin: 0;
        font-weight: 700;
    }
    .main-header p {
        color: #e0e0e0;
        font-size: 1.2rem;
        margin-top: 0.5rem;
    }
    </style>
    """, unsafe_allow_html=True)

# --- 2. ×¤×•× ×§×¦×™×•×ª AI ×•××©×™×›×ª ××™×“×¢ ---

if "GOOGLE_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
else:
    st.error("ğŸš¨ ×—×¡×¨ API Key ×‘×ª×™×§×™×™×ª ×”-Secrets ×©×œ Streamlit!")
    st.stop()

@st.cache_resource
def get_available_models():
    try:
        models = {}
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                name = m.name
                if 'gemini-3' in name.lower():
                    clean_name = name.split('models/')[1]
                    if 'pro' in clean_name:
                        models[f"ğŸ§  {clean_name} (××¢××™×§, ××•××œ×¥)"] = name
                    elif 'think' in clean_name:
                        models[f"ğŸ¤” {clean_name} (×”×¡×§×” ×•×—×©×™×‘×”)"] = name
                    elif 'flash' in clean_name:
                        models[f"âš¡ {clean_name} (××”×™×¨)"] = name
                    else:
                        models[clean_name] = name
        return models
    except: return {}

@st.cache_data(show_spinner=False)
def get_url_text(url):
    try:
        response = requests.get(url, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        for script in soup(["script", "style"]): script.decompose()
        return f"\n--- ×ª×•×›×Ÿ ××”××ª×¨ {url} ---\n" + soup.get_text()
    except: return ""

@st.cache_data(show_spinner=False)
def get_youtube_text(url):
    try:
        if "v=" in url: video_id = url.split("v=")[1].split("&")[0]
        else: video_id = url.split("/")[-1]
        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['he', 'en'])
        text = " ".join([t['text'] for t in transcript])
        return f"\n--- ×ª××œ×•×œ ××™×•×˜×™×•×‘ {url} ---\n" + text
    except: return ""

@st.cache_data(show_spinner=False)
def get_pdf_text():
    text = ""
    pdf_folder = "pdfs"
    if os.path.exists(pdf_folder):
        for filename in [f for f in os.listdir(pdf_folder) if f.endswith(".pdf")]:
            try:
                with open(os.path.join(pdf_folder, filename), 'rb') as f:
                    pdf_reader = PyPDF2.PdfReader(f)
                    for page in pdf_reader.pages:
                        content = page.extract_text()
                        if content: text += content + "\n"
            except: continue
    return text

@st.cache_data(show_spinner=False)
def get_links_content():
    combined_text = ""
    if os.path.exists('links.txt'):
        with open('links.txt', 'r', encoding='utf-8') as f:
            for link in f.readlines():
                link = link.strip()
                if not link: continue
                if "youtube.com" in link or "youtu.be" in link:
                    combined_text += get_youtube_text(link)
                else:
                    combined_text += get_url_text(link)
    return combined_text

# --- 3. ×× ×•×¢ RAG ×—×›× (×–×™×›×¨×•×Ÿ ×•×—×™×¤×•×© ×‘-RAM) ---

def chunk_text(text, chunk_size=1500, overlap=300):
    """×—×•×ª×š ××ª ×”××™×“×¢ ×œ××§×˜×¢×™× ×¢× ×—×¤×™×¤×” ×›×“×™ ×œ× ×œ×¤×¡×¤×¡ ×”×§×©×¨"""
    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunks.append(text[start:end])
        start += chunk_size - overlap
    return chunks

def retrieve_top_chunks(query, chunks, top_k=20):
    """×©×•×œ×£ ××ª ×”××§×˜×¢×™× ×”×¨×œ×•×•× ×˜×™×™× ×‘×™×•×ª×¨ ××ª×•×š ×”×–×™×›×¨×•×Ÿ ×‘×××¦×¢×•×ª ××œ×’×•×¨×™×ª× TF-IDF"""
    if not chunks: return ""
    if len(chunks) <= top_k: return "\n...\n".join(chunks)
    
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(chunks + [query])
    cosine_similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1]).flatten()
    
    # ×©×œ×™×¤×ª ×”××™× ×“×§×¡×™× ×©×œ ×”××§×˜×¢×™× ×¢× ×”×¦×™×•×Ÿ ×”×’×‘×•×” ×‘×™×•×ª×¨
    top_indices = cosine_similarities.argsort()[-top_k:][::-1]
    
    # ×¡×™×“×•×¨ ××—×“×© ×œ×¤×™ ×¡×“×¨ ×”×•×¤×¢×” ×‘××¡××š ×›×“×™ ×œ×©××•×¨ ×¢×œ ×¨×¦×£ ×§×¨×™××” ×”×’×™×•× ×™ ×œ××•×“×œ
    top_indices = sorted(top_indices) 
    return "\n...\n".join([chunks[i] for i in top_indices])

# --- 4. ×œ×•×’×™×§×” ×•×××©×§ ××¨×›×–×™ ---

st.markdown("""
    <div class="main-header">
        <h1>âš™ï¸ ××¨×›×– ×™×“×¢ ×”× ×“×¡×™ - Senior</h1>
        <p>××¢×¨×›×ª RAG ×—×›××” ××‘×•×¡×¡×ª Gemini 3 | ×”×›× ×” ×œ×¨××™×•× ×•×ª ×ª×›×Ÿ ××›× ×™</p>
    </div>
""", unsafe_allow_html=True)

categories = {
    "××™×¤×™×•×Ÿ ×“×¨×™×©×•×ª, ××™××•×ª ×•×ª×™×§×•×£ (V&V)": "×¤×¨×˜ ×œ×¢×•××§ ×¢×œ PRD/TRD, ××•×“×œ ×”-V, Verification ××•×œ Validation ×•×’×–×™×¨×ª ×“×¨×™×©×•×ª.",
    "×©×œ×‘×™ ×¤×™×ª×•×— ××•×¦×¨ ×•×‘×“×™×§×•×ª": "×”×¨×—×‘ ×××•×“ ×¢×œ PDR, CDR, NPI, ×•×‘×“×™×§×•×ª ATP, QTP ×•-ESS ×›×•×œ×œ ××ª×•×“×•×œ×•×’×™×•×ª.",
    "× ×™×”×•×œ ×¡×™×›×•× ×™× ×”× ×“×¡×™": "×¡×›× ×‘×¤×™×¨×•×˜ ×¨×‘ × ×™×”×•×œ ×¡×™×›×•× ×™× ×˜×›× ×™, FMEA ×•×“×’××™ ×”×™×ª×›× ×•×ª POD.",
    "×˜×›× ×•×œ×•×’×™×•×ª ×™×™×¦×•×¨": "×¤×¨×˜ ×¢×œ CNC, ×™×¦×™×§×•×ª, DFM ×•×”×“×¤×¡×•×ª ×ª×œ×ª-×××“ ×›×•×œ×œ ×©×™×§×•×œ×™ ×‘×—×™×¨×” ×”× ×“×¡×™×™×.",
    "×¡×•×‘×œ× ×•×™×•×ª ×•-GD&T": "×¤×¨×˜ ×œ×¢×•××§ ×¢×œ ×‘×§×¨×•×ª ×’×™××•××˜×¨×™×•×ª, ×¦×‘×™×¨×ª ×˜×•×œ×¨× ×¡×™× RSS/Worst Case ×•×”×ª×××•×ª Fits.",
    "×§×•×¨×•×–×™×”, ×¦×™×¤×•×™×™× ×•×˜×™×¤×•×œ×™ ×©×˜×—": "×¡×›× ×‘×”×¨×—×‘×” ×× ×’× ×•× ×™ ×§×•×¨×•×–×™×”, ×‘×—×™×¨×ª ×¦×™×¤×•×™×™× ×•×× ×™×¢×ª ×”×™×ª×¤×¡×•×ª (Galling).",
    "×ª×›×Ÿ ×œ××˜×™××•×ª (IP & EMI)": "×¤×¨×˜ ×œ×¢×•××§ ×¢×œ ××˜×™××” ×¡×‘×™×‘×ª×™×ª, ×¡×™×›×•×š EMI, ×—×¨×™×¦×™× ×•××˜××™×.",
    "×©×™×§×•×œ×™ ×ª×›×Ÿ ×ª×¨××™": "×”×¨×—×‘ ×××•×“ ×¢×œ ×× ×’× ×•× ×™ ×”×¢×‘×¨×ª ×—×•×, × ×™×”×•×œ ×ª×¨××™ ×‘×××¨×–×™× ×•×—×™×©×•×‘×™ ×˜××¤×¨×˜×•×¨×ª ×¦×•××ª.",
    "×ª×›×Ÿ ×¤×œ×¡×˜×™×§ ×•×—×•××¨×™×": "×¡×›× ×ª×›×Ÿ ×œ×”×–×¨×§×ª ×¤×œ×¡×˜×™×§, ×–×•×•×™×•×ª ×—×œ×™×¦×”, ×¤×’××™× ×•×¤×•×œ×™××¨×™× ×”× ×“×¡×™×™×.",
    "×ª×›×Ÿ ×›×¨×˜×™×¡×™× ××œ×§×˜×¨×•× ×™×™× (PCB)": "×¤×¨×˜ ×œ×¢×•××§ ×¢×œ ×–×™×•×•×“ ×›×¨×˜×™×¡×™×, Rigid-Flex ×•××’×‘×œ×•×ª ×™×™×¦×•×¨.",
    "×”×™×‘×˜×™ ×¢×œ×•×ª ×•× ×™×”×•×œ ×¤×¨×•×™×§×˜": "×¡×›× ×ª×”×œ×™×›×™ DTC, ×©×™××•×© ×‘-COTS ×•××‘× ×” ×ª×•×›× ×™×•×ª ×¢×‘×•×“×” (×’×× ×˜).",
    "×× ×œ×™×–×•×ª ×•×—×™×©×•×‘×™× ×”× ×“×¡×™×™×": "×¤×¨×˜ ×¢×œ ×× ×œ×™×–×•×ª Von Mises, ×¨×¢×™×“×•×ª ×•×”×œ××™× ×•×—×™×©×•×‘×™× ×ª×¨××•-××›× ×™×™×.",
    "×ª×›×Ÿ ×œ×”×¨×›×‘×ª×™×•×ª ×•×××™× ×•×ª (DFA/DFS)": "×¡×›× ×©×™×˜×•×ª ×œ×¦××¦×•× ×˜×¢×•×™×•×ª ×”×¨×›×‘×”, × ×’×™×©×•×ª ×œ×›×œ×™ ×¢×‘×•×“×” ×•×ª×—×–×•×§×ª×™×•×ª."
}

available_models = get_available_models()

with st.sidebar:
    st.header("ğŸ›ï¸ ×¤×× ×œ ×©×œ×™×˜×”")
    
    if not available_models:
        st.error("ğŸš¨ ×œ× ×”×¦×œ×—×ª×™ ×œ××©×•×š ××•×“×œ×™× ××”×©×¨×ª. ×‘×“×•×§ ××ª ×”-API Key.")
        st.stop()
        
    selected_model_display = st.selectbox("×‘×—×¨ ××•×“×œ ×¢×™×‘×•×“ ××•×¨×©×”:", list(available_models.keys()))
    working_model = available_models[selected_model_display]
    
    st.divider()
    st.subheader("×”×’×“×¨×•×ª ×¡×™×›×•×")
    category = st.selectbox("× ×•×©× ×¨××©×™ (×¡×™×œ×‘×•×¡):", list(categories.keys()))
    focus_text = st.text_input("××™×§×•×“ ×¡×¤×¦×™×¤×™ (××•×¤×¦×™×•× ×œ×™):", placeholder="×œ××©×œ: ×ª×ª××§×“ ×‘×—×™×©×•×‘×™ O-ring...")
    
    st.divider()
    generate_btn = st.button("ğŸš€ ×”×¤×§ ×¡×™×›×•× ××§×™×£", type="primary", use_container_width=True)

if generate_btn:
    with st.spinner(f"×‘×•× ×” ××™× ×“×§×¡, ××—×¤×© ××§×•×¨×•×ª ×•××¢×‘×“ × ×ª×•× ×™× ×‘×¢×–×¨×ª {selected_model_display}..."):
        
        # 1. ×˜×¢×™× ×ª ×›×œ ×”×—×•××¨
        raw_content = get_pdf_text() + get_links_content()
        
        if raw_content.strip():
            try:
                # 2. ×—×™×ª×•×š ×”×—×•××¨ ×•×©×œ×™×¤×” ×—×›××” ×©×œ ×”-20 ××§×˜×¢×™× ×”×¨×œ×•×•× ×˜×™×™× ×‘×™×•×ª×¨
                chunks = chunk_text(raw_content)
                search_query = focus_text if focus_text.strip() else category
                relevant_content = retrieve_top_chunks(search_query, chunks)
                
                # 3. ×”×’×“×¨×ª ×”×ª×¦×•×¨×” (××§×¡×™××•× ×˜×•×§× ×™× ×¤×œ×˜, ×˜××¤×¨×˜×•×¨×” × ××•×›×” ×œ×“×™×•×§)
                generation_config = genai.types.GenerationConfig(
                    max_output_tokens=8192,
                    temperature=0.3
                )
                model = genai.GenerativeModel(working_model, generation_config=generation_config)
                
                if focus_text.strip():
                    task_instruction = f"××©×™××”: ×”×œ×§×•×— ×‘×—×¨ ×‘×§×˜×’×•×¨×™×™×ª '{category}', ××š ×‘×™×§×© ×œ××§×“ ××ª ×”×¡×™×›×•× ××š ×•×¨×§ ×‘× ×•×©× ×”×‘×: {focus_text}. ×”×ª×¢×œ× ××©××¨ × ×•×©××™ ×”×§×˜×’×•×¨×™×”. ×¡×¤×§ ×¦×œ×™×œ×ª ×¢×•××§ ×”× ×“×¡×™×ª ×•××¤×•×¨×˜×ª ×œ× ×•×©× ×–×” ×‘×œ×‘×“."
                else:
                    task_instruction = f"××©×™××”: {categories[category]}"
                
                prompt = f"""
                ××ª×” ××”× ×“×¡ ××›×•× ×•×ª ×‘×›×™×¨ ×•××“×¨×™×š ×˜×›× ×™. ×”××˜×¨×” ×©×œ×š ×”×™× ×œ×™×™×¦×¨ ××¡××š ×œ×™××•×“ ××§×™×£, ××¢××™×§ ×•××¤×•×¨×˜ ×›×›×œ ×”××¤×©×¨.
                ××™×¡×•×¨ ××•×—×œ×˜ ×¢×œ ×ª××¦×•×ª: ××œ ×ª×©××™×˜ ×©×•× ×¤×¨×˜ ×˜×›× ×™, ×”×¡×‘×¨ ×× ×’× ×•× ×™× ×œ×¢×•××§ ×•××œ ×ª×“×œ×’ ×¢×œ ×©×œ×‘×™× ×‘×ª×™××•×¨.
                
                {task_instruction}
                
                ×”× ×—×™×•×ª ×§×¨×™×˜×™×•×ª ×œ×‘×™×¦×•×¢:
                1. ×”×ª×‘×¡×¡ ××š ×•×¨×§ ×¢×œ ×”××™×“×¢ ××”××§×•×¨×•×ª ×©×¡×•×¤×§×• ×œ××˜×”.
                2. ×”×¡×‘×¨ ×‘×”×¨×—×‘×” ××ª ×”×œ×•×’×™×§×” ×”×”× ×“×¡×™×ª ("×”×œ××”" ×•"×”××™×š"). ×¦×œ×•×œ ×œ×¤×¨×˜×™× ×”××™×§×¨×•×¡×§×•×¤×™×™× ×•×”××§×¨×•×¡×§×•×¤×™×™×.
                3. ×—×œ×§ ××ª ×”×ª×©×•×‘×” ×œ×›×•×ª×¨×•×ª ×¨××©×™×•×ª, ×›×•×ª×¨×•×ª ××©× ×”, ×•×¨×©×™××•×ª ×‘×•×œ×˜×™× ××¨×•×›×•×ª ×•××¤×•×¨×˜×•×ª.
                4. **×”× ×—×™×” ×œ××©×•×•××•×ª:** ×›×œ × ×•×¡×—×” ××ª××˜×™×ª ×—×™×™×‘×ª ×œ×”×™×›×ª×‘ ×‘-LaTeX ×¡×˜× ×“×¨×˜×™ ××©×××œ ×œ×™××™×Ÿ. ×”×©×ª××© ×‘- $ ×¢×‘×•×¨ ××©×•×•××” ×‘×ª×•×š ×”×©×•×¨×”, ×•×‘- $$ ×œ××©×•×•××” ×××•×¨×›×–×ª ×‘×©×•×¨×” × ×¤×¨×“×ª.
                5. ×¡×¤×§ ×ª×©×•×‘×” ××¨×•×›×” ×××•×“ ×‘×¨××ª Senior Mechanical Engineer.
                
                ×”××§×•×¨×•×ª ×©× ×©×œ×¤×• ××”×××’×¨ ×©×œ×š:
                ---
                {relevant_content}
                ---
                ×›×ª×•×‘ ×‘×¢×‘×¨×™×ª ×˜×›× ×™×ª ×‘×¨××” ×’×‘×•×”×” ×××•×“.
                """
                response = model.generate_content(prompt)
                
                display_title = f"ğŸ“š × ×•×©×: {category}"
                if focus_text.strip():
                    display_title += f" | ××™×§×•×“: {focus_text}"
                    
                st.subheader(display_title)
                
                with st.container(border=True):
                    st.markdown(response.text)
                    
            except Exception as e:
                st.error(f"×©×’×™××” ×‘×”×¤×§×ª ×”×ª×•×›×Ÿ (×™×ª×›×Ÿ ×•×—×¨×™×’×ª ××›×¡×” ×× × ×‘×—×¨×• ××•×“×œ×™× ×›×‘×“×™× ××“×™ ×‘×¨×¦×£): {e}")
        else:
            st.warning("×œ× × ××¦× ×ª×•×›×Ÿ ×‘××§×•×¨×•×ª ×©×œ×š ×‘-GitHub (×ª×™×§×™×™×ª pdfs ××• ×§×•×‘×¥ links.txt).")
